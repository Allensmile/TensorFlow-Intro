{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Classify Manhattan with TensorFlow\n",
    "\n",
    "In this codelab, we will use TensorFlow to train a neural network to predict whether a geolocation is in Manhattan or not, by looking at its longitude and latitude.\n",
    "\n",
    "<br/>\n",
    "![](images/manhattan.png)\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labs and Solutions\n",
    "\n",
    "In this codelab there are several Labs where you need to write your code to solve the problems. If you need some hints, you may take a look at the [Solution](2.%20Classify%20Manhattan%20with%20TensorFlow%20_Solution_.ipynb) page to see the answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update TensorFlow to version 1.0 or above\n",
    "\n",
    "To check the version of TensorFlow in your Cloud Datalab, **select the cell below and run the code by clicking \"Run\" on the menu**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This codelab requires TensorFlow 1.0 or above. If you see older versions such as 0.11.0rc0, please follow the instruction below to update your local Datalab.\n",
    "\n",
    "- Stop your Datalab by pressing Ctrl+C on the console\n",
    "- Run the following command on the console\n",
    "```\n",
    "> docker pull gcr.io/cloud-datalab/datalab:local\n",
    "```\n",
    "- Run the [`docker run`](https://cloud.google.com/datalab/docs/quickstarts/quickstart-local#install_the_datalab_docker_container_on_your_computer) command to restart local Datalab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2-1. Importing the training data from BigQuery\n",
    "\n",
    "At first, we will download a training data from [BigQuery](https://cloud.google.com/bigquery/), a fully managed scalable data warehouse service on Google Cloud. BigQuery provides many kinds of [public datasets](https://cloud.google.com/bigquery/public-data/) which is useful datasource for learning data analytics with BigQuery and TensorFlow.\n",
    "\n",
    "One of the public datasets is [NYPD Motor Vehicle Collisions Data](https://cloud.google.com/bigquery/public-data/nypd-mv-collisions) which collects all the car accidents happened in NYC from 2012 to the present. In this codelab, we will use it for getting 10,000 pairs of \"borough\" column and \"latitude/longitude\" columns.\n",
    "\n",
    "Let's take a look at the data by executing a BigQuery SQL. In Cloud Datalab, you can execute it by using \"%%sql\" command (see [this doc](https://github.com/googledatalab/notebooks/tree/master/tutorials/BigQuery) to learn more about the BigQuery commands). **Select the cell below and run the query** by clicking \"Run\" on the menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql -d standard\n",
    "SELECT\n",
    "  timestamp,\n",
    "  borough,\n",
    "  latitude,\n",
    "  longitude\n",
    "FROM\n",
    "  `bigquery-public-data.new_york.nypd_mv_collisions`\n",
    "ORDER BY\n",
    "  timestamp DESC\n",
    "LIMIT\n",
    "  15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess the training data on BigQuery\n",
    "\n",
    "In this codelab, we do not care about the car accidents. We just wanted to use the data for getting pairs of \"latitude\", \"longitude\" and \"Is it Manhattan or not\". So, we want to do the following preprocessing on this raw data:\n",
    "\n",
    "- Add a column \"is_mt\" that returns 1 or 0 to indicate if the borough is Manhattan or not\n",
    "- Remove rows without borough info\n",
    "- Remove rows without longitude/latitude info\n",
    "- Remove rows for Bronx (as it's too close to Manhattan and hard to classify with single layer neural network!)\n",
    "- Randomly shuffule all the rows (for making the training data even)\n",
    "- Select only the 10,000 rows\n",
    "\n",
    "So, our SQL with the preprocessing will look like the following. **Select the cell below and run it**. Please note that this only defines the SQL module \"nyc_collisions\" that will be used later and **does not output anything**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%sql --module nyc_collisions\n",
    "SELECT\n",
    "  IF(borough = 'MANHATTAN', 1, 0) AS is_mt,\n",
    "  latitude,\n",
    "  longitude\n",
    "FROM\n",
    "  `bigquery-public-data.new_york.nypd_mv_collisions`\n",
    "WHERE\n",
    "  LENGTH(borough) > 0\n",
    "  AND latitude IS NOT NULL AND latitude != 0.0\n",
    "  AND longitude IS NOT NULL AND longitude != 0.0\n",
    "  AND borough != 'BRONX'\n",
    "ORDER BY\n",
    "  RAND()\n",
    "LIMIT\n",
    "  10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the BigQuery SQL result as NumPy array\n",
    "\n",
    "Then, we need to execute the SQL defined above and import the data into Datalab. For this purpose, Datalab provides [BigQuery APIs](https://github.com/googledatalab/notebooks/blob/master/tutorials/BigQuery/BigQuery%20APIs.ipynb) that allows you to execute the define SQL and import the results as a [NumPy](http://www.numpy.org/) array named `nyc_cols`. **Run the cell below** and confirm it loaded 10,000 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datalab.bigquery as bq\n",
    "nyc_cols = bq.Query(nyc_collisions).to_dataframe(dialect='standard').as_matrix()\n",
    "print(nyc_cols)\n",
    "print(\"\\nLoaded \" + str(len(nyc_cols)) + \" rows.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at what's inside the result. **Run the cell below** and check the variable `is_mt` has an array of 1s and 0s representing each geolocation is in Manhattan or not, and the variable `latlng` has an array of pairs of latitude and longitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "is_mt = nyc_cols[:,0].astype(np.int32) # read the 0th column (is_mt) as int32\n",
    "latlng = nyc_cols[:,1:3].astype(np.float32) # read the 1st and 2nd column (latitude and longitude) as float32\n",
    "print(\"Is Manhattan: \" + str(is_mt))\n",
    "print(\"\\nLat/Lng: \\n\\n\" + str(latlng))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Lab: NumPy basics\n",
    "\n",
    "(You can skip this lab if you know how to use NumPy)\n",
    "\n",
    "You might notice that we just used NumPy for extracting the results. NumPy is the most popular Python library for numerical calculations. For machine learning with Python, many people are using NumPy for wide variety of numerical operations, including the basic array operations such as reshaping, merging, splitting, filtering, slicing and indexing. Many of TensorFlow APIs are also influenced by NumPy and use similar concepts. If you want to learn machine learning and TensorFlow with Python, we recommend you to learn [the basics of NumPy](https://docs.scipy.org/doc/numpy-dev/user/quickstart.html).\n",
    "\n",
    "In this lab, Let's try a few basic array operations with NumPy. **Run the cell below** and see what kind of numpy array will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create an numpy array with numbers from 0 to 14\n",
    "A = np.arange(15)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, please write and run code in the following cells to get the result described in the comments with NumPy. You may refer to the [NumPy Quickstart](https://docs.scipy.org/doc/numpy-dev/user/quickstart.html) to learn how to write those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reshape the array A into an array with shape in 3 rows and 5 columns,\n",
    "# set it to variable A, and print it.\n",
    "\n",
    "# *** ADD YOUR CODE HERE ***\n",
    "\n",
    "print(A)\n",
    "\n",
    "# expected result:\n",
    "# [[ 0  1  2  3  4]\n",
    "#  [ 5  6  7  8  9]\n",
    "#  [10 11 12 13 14]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print the shape, data type name, size (total number of elements) of the array A\n",
    "\n",
    "# *** ADD YOUR CODE HERE ***\n",
    "\n",
    "# expected result:\n",
    "# (3, 5)\n",
    "#  int64\n",
    "# 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# multiply the array A with a number 2 and print it\n",
    "\n",
    "# *** ADD YOUR CODE HERE ***\n",
    "\n",
    "# expected result:\n",
    "# [[ 0  2  4  6  8]\n",
    "#  [10 12 14 16 18]\n",
    "#  [20 22 24 26 28]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a new array that has the same shape as the array A filled with zeros, and print it\n",
    "\n",
    "# *** ADD YOUR CODE HERE ***\n",
    "\n",
    "# expected result:\n",
    "# [[ 0.  0.  0.  0.  0.]\n",
    "#  [ 0.  0.  0.  0.  0.]\n",
    "#  [ 0.  0.  0.  0.  0.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a new array that has the elements in the right most column of the array A\n",
    "\n",
    "# *** ADD YOUR CODE HERE ***\n",
    "\n",
    "# expected result:\n",
    "# [ 4  9 14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Collect elements in array B with an index \"I % 2 == 0\" and print it\n",
    "B = np.arange(10)\n",
    "I = np.arange(10)\n",
    "\n",
    "# *** ADD YOUR CODE HERE ***\n",
    "\n",
    "# expected result:\n",
    "# [0 2 4 6 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2-2. Feature scaling and splitting data\n",
    "\n",
    "Now we got the training data. But it's not ready for training a neural network model yet. If you use the raw data directly, you would fail on the training because the scales of each feature (latitude and longitude in this case) are quite different. \n",
    "\n",
    "In machine learning, usually you need to preprocess the raw data with [feature scaling](https://en.wikipedia.org/wiki/Feature_scaling) to normalize the feature data to have the same scale. So that it gets much easier for machine learning algorithms to compare those features and find relationships between them.\n",
    "\n",
    "In this codelab, we will use [StandardScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler) in [scikit-learn](http://scikit-learn.org/). Scikit-learn is another popular library for machine learning in Python that provides wide variety of training algorithms, preprocessing and validation tools. \n",
    "\n",
    "The StandardScaler scales the features so that their mean value will be 0 and standard deviation will be 1. This scaling is called **Standardization**. Let's **Run the cell below** and see how it scales the latitudes and longitudes and stores them into a variable `latlng_std`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "latlng_std = StandardScaler().fit_transform(latlng)\n",
    "print(latlng_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Lab: check the standardized feature values\n",
    "\n",
    "- Print mean and standard deviation values on both latitude and longitude of variable `latlng_std` by using NumPy and confirm the mean is almost 0 and standard deviation is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# *** ADD YOUR CODE HERE ***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Plot the training data with Matplotlib\n",
    "\n",
    "Now, all the preprocessing on the training data have finished. Let's see how it looks like by using [Matplotlib](http://matplotlib.org/), the popular visualization library for Python. In this case we will use [scatter()](http://matplotlib.org/api/pyplot_api.html#matplotlib.pyplot.scatter) method to plot dots with the pairs of latitude and longitude. **Run the cell below** and see the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "lat = latlng_std[:,0]\n",
    "lng = latlng_std[:,1]\n",
    "plt.scatter(lng[is_mt == 1], lat[is_mt == 1], c='b') # plot points in Manhattan in blue\n",
    "plt.scatter(lng[is_mt == 0], lat[is_mt == 0], c='y') # plot points outside Manhattan in yellow\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the geolocations in Manhattan are plotted in blue dots, and others are in yellow dots. Also, latitudes and longitudes are scaled to have 0 as the center."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into \"Training Data\" and \"Test Data\"\n",
    "\n",
    "Before start training the neural network model, we need to separate a part of the training data as test data. The test data will be used for checking accuracy of classifications by the model after the training. This is a common practice in machine learning to accurately evaluate the performance of your model.\n",
    "\n",
    "**Run the cell below** and split the data into 8,000 pairs of training data and 2,000 pairs of test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 8,000 pairs for training\n",
    "latlng_train = latlng_std[0:8000]\n",
    "is_mt_train = is_mt[0:8000]\n",
    "\n",
    "# 2,000 pairs for test\n",
    "latlng_test = latlng_std[8000:10000]\n",
    "is_mt_test = is_mt[8000:10000]\n",
    "\n",
    "print(\"Split finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Lab: Disscuss the preprocessing\n",
    "\n",
    "Disscuss with your buddy about the following topics.\n",
    "\n",
    "- What are the proprocess we have done so far\n",
    "- Why is each proprocess required\n",
    "- What function of NumPy and Matplotlib we have used to plot the map\n",
    "- Why we need to split the data into training and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2-3. Train the Neural Network with TensorFlow High level API\n",
    "\n",
    "<br/>\n",
    "![](images/tflogo.png)\n",
    "<br/>\n",
    "\n",
    "Now, let's use [TensorFlow](https://www.tensorflow.org/).\n",
    "\n",
    "TensorFlow is an open source library for machine learning. You can define your own neural network or deep learning model and run a training for it on your laptop, or on [many CPUs and GPUs in the cloud](https://cloud.google.com/ml/) for scalable and faster training and prediction.\n",
    "\n",
    "TensorFlow provides two kind of APIs:\n",
    "\n",
    "- [High level API](https://www.tensorflow.org/get_started/tflearn): provides easy-to-use [predefined machine learning models](https://www.tensorflow.org/api_guides/python/contrib.learn#estimators)\n",
    "- [Low level API](https://www.tensorflow.org/get_started/get_started): provides customizable data flow computation framework for machine learning\n",
    "\n",
    "If you will use common neural network and machine learning models (such as fully-connected neural network, convolutional neural network, logistic regression and k-means), the high level API is recommended. If you want to design your own neural network model with sophisticated or new algorithm, or if you like to learn the underlying technology used for implementing the high level API, the low level API is the best option.\n",
    "\n",
    "In this codelab, we will use the high level API first, and then look at the low level API to learn more about the underlying technology."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a single layer neural network\n",
    "\n",
    "**Run the cell below** to define a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR) # supress warning messages\n",
    "\n",
    "# define two feature columns with real values\n",
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=2)]\n",
    "\n",
    "# create a neural network\n",
    "dnnc = tf.contrib.learn.DNNClassifier(\n",
    "  feature_columns=feature_columns,\n",
    "  hidden_units=[],\n",
    "  n_classes=2)\n",
    "\n",
    "dnnc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above does the following:\n",
    "\n",
    "- At line 2, setting the log level to ERROR to supress warning messages\n",
    "- At line 5, defining \"feature columns\" (columns in the training data used for training the model) as two dimensional real values\n",
    "- At line 8, defining a neural network by using [DNNClassifier](https://www.tensorflow.org/api_docs/python/tf/contrib/learn/DNNClassifier) class with the following parameters:\n",
    " - No hidden units (= fully connected single layer neural network)\n",
    " - Use two classes for classification (Manhattan or not)\n",
    " \n",
    "In a nutshell, this code defines a neural network like this, which is the same single neuron we tried with the Playground, where we put latitude and longitude as input to x1 and x2 respectively.\n",
    "\n",
    "<br/>\n",
    "![](images/singleneuron.png)\n",
    "![](images/nnformula.png)\n",
    "<br/>\n",
    "\n",
    "Just like we saw on the Playground, the neuron can classify each datapoint into two groups by drawing **a single straight line**. While training this neuron with the training data, the neuron tries to move the weight and bias values to find what's the best angle and position for the line to classify Manhattan correctly.\n",
    "\n",
    "<br/>\n",
    "![](https://cloud.google.com/blog/big-data/2016/07/images/146798944178238/neuralnetworks-22.png)\n",
    "<br/>\n",
    "\n",
    "This time, we will train the neuron for classifying whether a geolocation is in Manhattan or not by drawing a line on the map with a single neuron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the accuracy of the neural network\n",
    "\n",
    "Before start training the neural network, let's define two methods for checking the accuracy of the neural network. **Run the cell below**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot a predicted map of Manhattan\n",
    "def plot_predicted_map():\n",
    "  is_mt_pred = dnnc.predict(latlng_std, as_iterable=False) # an array of prediction results\n",
    "  plt.scatter(lng[is_mt_pred == 1], lat[is_mt_pred == 1], c='b')\n",
    "  plt.scatter(lng[is_mt_pred == 0], lat[is_mt_pred == 0], c='y')\n",
    "  plt.show()\n",
    "\n",
    "# print the accuracy of the neural network \n",
    "def print_accuracy():\n",
    "  accuracy = dnnc.evaluate(x=latlng_test, y=is_mt_test)[\"accuracy\"]\n",
    "  print('Accuracy: {:.2%}'.format(accuracy))\n",
    "  \n",
    "# train the model just for 1 step and print the accuracy\n",
    "dnnc.fit(x=latlng_train, y=is_mt_train, steps=1)\n",
    "plot_predicted_map()\n",
    "print_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first method `plot_predicted_map()` at line 3, it calls [predict()](https://www.tensorflow.org/api_docs/python/tf/contrib/learn/DNNClassifier#predict) method of `DNNClassifier` class to get an array of prediction results (10,000 rows) like `[1 0 0 1 ... 0 0 1 0]` where `1` means that the neural network believes the geolocation is in Manhattan, and `0` means it's not. By using this array as index for selecting `lat` and `lng`, the method plots geolocations predicted as Manhattan in blue dots and others in yellow dots.\n",
    "\n",
    "In the second method `print_accuracy()` at line 9, it calls [evaluate()](https://www.tensorflow.org/api_docs/python/tf/contrib/learn/Evaluable#evaluate) method of `DNNClassifier` class to calculate the accuracy of the prediction with the test data `latlng_test` and `is_mt_test` and print it.\n",
    "\n",
    "After defining the two methods, it calls [fit()](https://www.tensorflow.org/api_docs/python/tf/contrib/learn/Trainable#fit) method of `DNNClassifier` class at line 14 to train the model for just **one step**. A step in the `fit()` method moves the weights and bias in the neural network only for a little towards the direction of less error. But usually it takes thousands of steps for neural networks to find the best weights and bias. So, what you are seeing shows how the neural network in the initial state (= before the training) gives so low accuracy and can not classify the Manhattan properly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the neural network\n",
    "\n",
    "Finally let's start training the neural network. This time, we will train the network by calling `fit()` method for 500 steps with the training data `latlng_train` and `is_mt_train`. At every 100 steps, it will call `plot_predicted_map()` and `print_accuracy()` to show the current accuracy of the network. **Run the cell below** and wait for a while until the message \"Finished\" is printed. You will see the network is trying to **move the weights and bias slowly** to minimize the error and find the best position of the line for classifying geolocations in Manhattan. The final accuracy would be as high as 97%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "steps = 100\n",
    "for i in range (1, 6):\n",
    "  dnnc.fit(x=latlng_train, y=is_mt_train, steps=steps)\n",
    "  plot_predicted_map()\n",
    "  print('Steps: ' + str(i * steps))\n",
    "  print_accuracy()\n",
    "  \n",
    "print('\\nTraining Finished.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Lab: Try training the neural network a couple of times\n",
    "\n",
    "- Go back to the section \"Define a single layer neural network\" and run the following cells again to train the network from scratch\n",
    "- Repeat the training for a couple of times and confirm that the network's max accuracy is around 97%\n",
    "- Discuss with your buddy what is the reason why the single layer network can't achieve accuracy higher than 97%. The single layer neural network is also known as **Perceptron**. You may refer to the [Wikipedia page for Perceptron](https://en.wikipedia.org/wiki/Perceptron) to learn more about its characteristics and limitations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2-4. Train a Deep Neural Network with TensorFlow\n",
    "\n",
    "You just saw that the network can only draw **a straight line** on the map and classify a geolocation is in Manhattan or not. So called **Linear Classification**. That is the limitation of the single layer neural network and you can only achieve around 97% accuracy because the straight line (linear classification) can't split the geolocations between Manhattan and Brooklyn with a curved boundary.\n",
    "\n",
    "We must go deeper. Let's define a deep neural network (DNN). **Run the cell below** to define a new `DNNClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dnnc = tf.contrib.learn.DNNClassifier(\n",
    "  feature_columns=feature_columns,\n",
    "  hidden_units=[20, 20, 20, 20],\n",
    "  n_classes=2)\n",
    "dnnc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The hidden layers give the power\n",
    "\n",
    "The only difference from the last `DNNClassifier` definition is the `hidden_units` parameter where it defines **4 hidden layers with 20 neurons each**. As the network has total 5 layers, you can call it as a deep neural network (\"deep\" means you have layers more than 2). \n",
    "\n",
    "Let's see how the deep neural network works. **Run the cell below** and wait for a couple of minutes until it finishes the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "steps = 30\n",
    "for i in range (1, 6):\n",
    "  dnnc.fit(x=latlng_train, y=is_mt_train, steps=steps)\n",
    "  plot_predicted_map()\n",
    "  print 'Steps: ' + str(i * steps)\n",
    "  print_accuracy()\n",
    "  \n",
    "print('\\nTraining Finished.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You just saw that a DNN can classify the geolocations of Manhattan at around 99.9% accuracy with a curved boundary that fits between Manhattan and Brooklyn. In the next section, we will learn why DNN can recognize and extract the complex patterns in the training dataset by using the power of **hidden layers**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Lab: Train the network with different configurations\n",
    "\n",
    "- Reduce the number of hidden layers to 3, 2 and 1 and retry training the network. See how it affect the accuracy\n",
    "- Reduce the number of nodes in all hidden layers to 10 and retry training the network. See how it affect the accuracy\n",
    "- Discuss with your buddy what is the reason why the deep neural network can achieve much higher accuracy than the single layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# What We Learned\n",
    "\n",
    "In this section, we have learned the following concepts.\n",
    "\n",
    "- With Cloud Datalab, you can execute **BigQuery SQLs** and import the result, easily able to **preprocess** the training data\n",
    "- In machine learning, the preprocessing such as **feature scaling** with **standardization** and **splitting into training data and test data** are important procedures before start the training\n",
    "- In machine learning with Python, you can use popular tools such as **NumPy**, **scikit-learn** and **Matplotlib** for those preprocessing and visualization\n",
    "- **TensorFlow** provides **High level API** and **Low level API**. You may choose the former for using the common machine learning and neural network models\n",
    "- **DNNClassifier** class of High-level API let you easily define, train and evaluate a neural network\n",
    "- Single layer neural network is a **Linear Classifier** so that it has a limitation on recognizing complex patterns in training data\n",
    "- By using **Deep Neural Network**, you can capture much complex patterns from the training data and can classify them with its **hidden layers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's Next?\n",
    "\n",
    "To learn more about the deep neural network, please proceed with [3. Why deep neural network can get smarter?](3.%20Why%20deep%20neural%20network%20can%20get%20smarter%3F.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
